{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from Stupid_digits import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD8CAYAAAA/iMxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABVlJREFUeJzt3cGN4zYYgNHYSBVbxTYx2AqmyqkgcBOpImVYuQVY5MJd\nU58o673zwBZozgce9IO3bdv+AKBzP/oBAK5GeAFiwgsQE16AmPACxIQXICa8ADHhBYgJL0Dsz6O+\n+OP+OTQy99c/f+/9KD/58e370N89nl+3nR/lJaPrO2L0NxhduxErr6+9u5+rrK0TL0BMeAFiwgsQ\nE16AmPACxIQXICa8ADHhBYgJL0DssMm1mUanSupplzOwJseaOe13JTPX7Yj/ASdegJjwAsSEFyAm\nvAAx4QWICS9ATHgBYsILEHuLAQpDAL9v5EV067ufmWt7pWGMs+9JJ16AmPACxIQXICa8ADHhBYgJ\nL0BMeAFiwgsQE16A2FtMrrn6h7Oyd/ez8iSfEy9ATHgBYsILEBNegJjwAsSEFyAmvAAx4QWIvcUA\nhZfLOSt7dz8rX6vkxAsQE16AmPACxIQXICa8ADHhBYgJL0BMeAFiwgsQu23bdvQzAFyKEy9ATHgB\nYsILEBNegJjwAsSEFyAmvAAx4QWIHXb1z8f9c9rkxugVHzOv73g8v27TPmwHo+tbXz0z+husvL72\n7n6usm+deAFiwgsQE16AmPACxIQXICa8ADHhBYgJL0DssAGKUfWL0vzfzJf3r2Rk746u7czPuoqV\n18OJFyAmvAAx4QWICS9ATHgBYsILEBNegJjwAsSWH6AYeQnakMW+Zq7vyi+1815W3rdOvAAx4QWI\nCS9ATHgBYsILEBNegJjwAsSEFyAmvACx5SfX2NfMiRwThKxk5rVKsznxAsSEFyAmvAAx4QWICS9A\nTHgBYsILEBNegJgBiosz9LCfmddWuTLp1628t514AWLCCxATXoCY8ALEhBcgJrwAMeEFiAkvQEx4\nAWK3bduOfgaAS3HiBYgJL0BMeAFiwgsQE16AmPACxIQXICa8ADHhBYgddufax/1zaGSuvjdp9G6r\nx/PrtvOjvMT67mfm2o6ux8zPusrazjR7bZ14AWLCCxATXoCY8ALEhBcgJrwAMeEFiAkvQOywAYpR\noy8uj6hfuj4D68u7mjmcMpsTL0BMeAFiwgsQE16AmPACxIQXICa8ADHhBYgtP0AxYvQF6JnDAldi\nffcz8+V9Ayw/W3k9nHgBYsILEBNegJjwAsSEFyAmvAAx4QWICS9ATHgBYm8xuTbzig/TV8xSX6s0\n+n2P56tPcw6u/gHgP8ILEBNegJjwAsSEFyAmvAAx4QWICS9AbPkBipWv7wDWtXI7nHgBYsILEBNe\ngJjwAsSEFyAmvAAx4QWICS9ATHgBYrdt245+BoBLceIFiAkvQEx4AWLCCxATXoCY8ALEhBcgJrwA\nMeEFiB1259rH/XNoZK6+N+nHt+9Df/d4ft12fpSXjK7viNHfYHTtRqy8vjP37uiazfysd1jbESvv\nWydegJjwAsSEFyAmvAAx4QWICS9ATHgBYsILEDtsgGKmmS+hX4014YzOvm+deAFiwgsQE16AmPAC\nxIQXICa8ADHhBYgJL0DsLQYozv4y9ZFGhk+s735mru2Vfqez71snXoCY8ALEhBcgJrwAMeEFiAkv\nQEx4AWLCCxATXoDYW0yuufqHFY3uyxEje3f0+x7PV5+GVznxAsSEFyAmvAAx4QWICS9ATHgBYsIL\nEBNegNhbDFAYjADOxIkXICa8ADHhBYgJL0BMeAFiwgsQE16AmPACxIQXIHbbtu3oZwC4FCdegJjw\nAsSEFyAmvAAx4QWICS9ATHgBYsILEBNegJjwAsSEFyAmvAAx4QWICS9ATHgBYsILEBNegJjwAsSE\nFyAmvAAx4QWICS9ATHgBYv8CbOERUwzrq0wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c475048d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X are mormalizied digits to have overall activity 10\n",
    "X,y = stupid_digits_dataset(100)\n",
    "plt.figure('data')\n",
    "for i in np.arange(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(X[i].reshape((5,5)), interpolation=None)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "import numpy as np\n",
    "from time import clock\n",
    "\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "def sv_json(obj, p,encoding=\"cp1251\"):\n",
    "    with codecs.open(p, \"w\",encoding=encoding) as f:\n",
    "        json.dump(obj,f,indent=1,ensure_ascii=0)\n",
    "        \n",
    "def ld_json(p,encoding=\"cp1251\"):\n",
    "    with codecs.open(p,\"r\",encoding=encoding) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "start_scope()\n",
    "\n",
    "time_per_image = 100*ms\n",
    "time_step = 0.1*ms\n",
    "tau = 10*ms # tau for neuron's voltage 'v'\n",
    "tau_I = 15*ms # tau for neuron's current 'I'\n",
    "tau_h = 50*ms # tau for neuron's treshold\n",
    "\n",
    "wmax = 1.\n",
    "decay = 0.001\n",
    "\n",
    "eqs_input_neuron = '''\n",
    "rates : Hz\n",
    "da/dt = -a/alpha : 1\n",
    "dtheta/dt = -theta/beta : 1\n",
    "diff = a - c_diff * theta : 1\n",
    "train :1\n",
    "'''\n",
    "\n",
    "eqs_output_neuron = '''\n",
    "dv/dt = (-v+I)/tau : 1 (unless refractory)\n",
    "dI_inp/dt = -I_inp/tau_I :1\n",
    "dI_intr/dt = -I_intr/tau_I :1\n",
    "I_teacher :1\n",
    "I = I_inp + I_intr + I_teacher : 1\n",
    "da/dt = -a/alpha : 1\n",
    "dtheta/dt = -theta/beta : 1\n",
    "diff = a - c_diff * theta : 1\n",
    "dhold_output/dt = -hold_output/tau_h  : 1\n",
    "fixed_hold_output = clip(hold_output, 1, 5) :1\n",
    "train :1\n",
    "'''\n",
    "#fixed_hold_output = clip(hold_output, 1, 100) :1\n",
    "\n",
    "eqs_input_syn = '''\n",
    "w : 1\n",
    "'''\n",
    "\n",
    "# equations that describe changes if presynaptic spike of the forward-riented synapse of input layer occures\n",
    "eqs_input_pre = '''\n",
    "I_inp_post += w * c_inp\n",
    "a_pre += 1./classes *1*ms/(alpha)\n",
    "theta_pre += 1./classes *1*ms/(beta)\n",
    "'''\n",
    "\n",
    "# equations that describe changes if postsynaptic spike of the forward synapse occures\n",
    "eqs_input_post = '''\n",
    "a_post += 1./n_input *1*ms/(alpha)\n",
    "theta_post += 1./n_input *1*ms/(beta)\n",
    "w = clip(w + train_post*(-decay + lr*diff_pre), 0, wmax)\n",
    "'''\n",
    "\n",
    "eqs_intrinsic_output_syn = '''\n",
    "w: 1\n",
    "'''\n",
    "\n",
    "# equations that describe changes if spike of the intr output synapse occures\n",
    "eqs_intrinsic_output_pre = '''\n",
    "I_intr_post += w * c_intr_out\n",
    "'''\n",
    "\n",
    "eqs_intrinsic_output_post = '''\n",
    "w = clip(w + train_pre*(-lr_intr*diff_pre), -wmax, 0)\n",
    "'''\n",
    "\n",
    "\n",
    "reset_output = '''\n",
    "v = 0\n",
    "hold_output += 0.1*classes\n",
    "'''\n",
    "\n",
    "class Perceptron(object):\n",
    "    def __init__(self, X, y, params_to_optimize, inits = None, monitor = None, cheat = False, mod = True, \n",
    "                high_verbosity=True):\n",
    "        \n",
    "        '''\n",
    "        X - np.array with shape (N samples, N features)\n",
    "        y - np.array with shape (N samples)\n",
    "        n_hiiden - number of hidden neurons\n",
    "        inits  - list of 2 lists that contain 'distribution' and 'condition' parameters \n",
    "        for input, intrinsic, output and intrinsic_output connections\n",
    "            Example: inits = [['equal_[0,1]', None], ['equal_[-1,0]', 'i!=j']]\n",
    "        monitor - dictionary with keys 'P', 'G', 'H' or connection names. Each key argument value is dictionary.\n",
    "        Contains a list of what parameters to record for the object in the key name and dt.\n",
    "            Example: monitor = {'H':{'variables':[['a','I'],'dt':25*ms, 'record':True]}}\n",
    "        cheat - True if you wanna use pretrained model with first layer initialized from some objects of training data\n",
    "        '''\n",
    "        \n",
    "        self.high_verbosity = high_verbosity\n",
    "        global alpha, beta, lr, lr_intr, c_inp, c_intr_out, c_diff, Teacher_amplitude\n",
    "\n",
    "        alpha = params_to_optimize['alpha']\n",
    "        beta = params_to_optimize['beta']\n",
    "        lr = params_to_optimize['lr']\n",
    "        lr_intr = params_to_optimize['lr_intr']\n",
    "        c_inp = params_to_optimize['c_inp']\n",
    "        c_intr_out = params_to_optimize['c_intr_out']\n",
    "        c_diff = params_to_optimize['c_diff']\n",
    "        Teacher_amplitude = params_to_optimize['Teacher_amplitude']\n",
    "        \n",
    "        self.X = X\n",
    "        if self.X is not None:\n",
    "            n_input = int(X.shape[1])\n",
    "        else:\n",
    "            raise ValueError('No data provided to the simulation')\n",
    "        \n",
    "        self.y = y\n",
    "        classes = int(len(set(y)))\n",
    "        \n",
    "        # list to store initial values for synapses in order [input, intrinsic, output, intrinsic_output]\n",
    "        if inits:\n",
    "            pass\n",
    "        else:\n",
    "            inits = [['equal_[0,1]', None], ['equal_[-1,0]', 'i!=j']]\n",
    "         \n",
    "        #creatitng the network: groups and synapses\n",
    "        \n",
    "        self.P = NeuronGroup(n_input, eqs_input_neuron, threshold='rand()<rates*dt', method='linear', \n",
    "                             refractory=2*ms, dt = time_step, name='P')\n",
    "        #experiment\n",
    "        self.M = NeuronGroup(n_input, eqs_input_neuron, threshold='rand()<rates*dt', method='linear',\n",
    "                             refractory=2*ms, dt = time_step, name='M')\n",
    "        self.H = NeuronGroup(classes, eqs_output_neuron, method=linear, threshold='v > fixed_hold_output', \n",
    "                             reset=reset_output, refractory=2*ms, dt=time_step, name = 'H')\n",
    "        self.create_synapse('input_syn', self.P, self.H, eqs_input_syn, eqs_input_pre, eqs_input_post,\n",
    "                           distribution=inits[0][0], condition=inits[0][1])\n",
    "        self.create_synapse('input_inverse_syn', self.M, self.H, eqs_input_syn, eqs_input_pre, eqs_input_post,\n",
    "                           distribution=inits[0][0], condition=inits[0][1])\n",
    "        self.create_synapse('intrinsic_output_syn', self.H, self.H, eqs_intrinsic_output_syn, \n",
    "                            eqs_intrinsic_output_pre, eqs_intrinsic_output_post, \n",
    "                            distribution=inits[1][0], condition=inits[1][1])\n",
    "        \n",
    "        # set random values to a and theta for all groups, set train parameter of the group to 1.\n",
    "        self.random_init_groups([self.P, self.M, self.H], [1, 1, 1])\n",
    "        \n",
    "        # operation to do during simulation every dt \n",
    "        self.network_op = NetworkOperation(self.update_func, dt=time_per_image)\n",
    "        \n",
    "        # params to give for constructing the simulation\n",
    "        params = [self.P, self.M, self.H, self.input_syn, self.input_inverse_syn, \n",
    "                  self.intrinsic_output_syn, self.network_op]\n",
    "        \n",
    "        self.monitor = monitor\n",
    "        # adding monitors to the simulation params\n",
    "        # TO DO: OPTIMIZE!!!!!\n",
    "        if self.monitor:\n",
    "            if 'P' in self.monitor.keys():\n",
    "                self.StateMonitorP = StateMonitor(self.P, self.monitor['P']['variables'], record=self.monitor['P']['record'],\n",
    "                                                  dt=monitor['P']['dt'],\n",
    "                                                  name = 'StateMonitorP')\n",
    "                params.append(self.StateMonitorP)\n",
    "            else:\n",
    "                self.StateMonitorP = None\n",
    "                \n",
    "            if 'M' in monitor.keys():\n",
    "                self.StateMonitorM = StateMonitor(self.M, self.monitor['M']['variables'], record=self.monitor['M']['record'], \n",
    "                                                  dt=monitor['M']['dt'],\n",
    "                                                  name = 'StateMonitorM')\n",
    "                params.append(self.StateMonitorM)\n",
    "            else:\n",
    "                self.StateMonitorM = None\n",
    "                \n",
    "            if 'H' in monitor.keys():\n",
    "                self.StateMonitorH = StateMonitor(self.H, self.monitor['H']['variables'], record=self.monitor['H']['record'], \n",
    "                                                  dt=monitor['H']['dt'],\n",
    "                                                  name = 'StateMonitorH')\n",
    "                params.append(self.StateMonitorH)\n",
    "            else:\n",
    "                self.StateMonitorH = None\n",
    "                \n",
    "            if 'Input_weights' in monitor.keys():\n",
    "                self.SynapseMonitorInput = StateMonitor(self.input_syn, self.monitor['Input_weights']['variables'], \n",
    "                                                        record=self.monitor['Input_weights']['record'],\n",
    "                                                        dt = monitor['Input_weights']['dt'],\n",
    "                                                        name = 'SynapseMonitorInput')\n",
    "                params.append(self.SynapseMonitorInput)\n",
    "            else:\n",
    "                self.SynapseMonitorInput = None\n",
    "                \n",
    "            if 'Input_inverse_weights' in monitor.keys():\n",
    "                self.SynapseMonitorInputInverse = StateMonitor(self.input_inverse_syn, self.monitor['Input_inverse_weights']['variables'], \n",
    "                                                        record=self.monitor['Input_inverse_weights']['record'],\n",
    "                                                        dt = monitor['Input_inverse_weights']['dt'],\n",
    "                                                        name = 'SynapseMonitorInputInverse')\n",
    "                params.append(self.SynapseMonitorInputInverse)\n",
    "            else:\n",
    "                self.SynapseMonitorInputInverse = None\n",
    "            \n",
    "            if 'Intrinsic_output_weights' in monitor.keys():\n",
    "                self.SynapseMonitorIntrinsicOutput = StateMonitor(self.intrinsic_output_syn, self.monitor['Intrinsic_output_weights']['variables'],\n",
    "                                                        record=self.monitor['Intrinsic_output_weights']['record'], \n",
    "                                                        dt = monitor['Intrinsic_output_weights']['dt'],\n",
    "                                                        name = 'SynapseMonitorIntrinsicOutput')\n",
    "                params.append(self.SynapseMonitorIntrinsicOutput)\n",
    "            else:\n",
    "                self.SynapseMonitorIntrinsicOutput = None\n",
    "        \n",
    "        # setting params to the simulation\n",
    "        self.network = Network(params)\n",
    "        if self.high_verbosity:\n",
    "            print ('Network created using:')\n",
    "            for param in params:\n",
    "                print ('\\t'+param.name + '   dt = '+str(param.clock.dt))\n",
    "            \n",
    "        self.shown_labels = [] #list to store shown labels during lifetime of the simulation\n",
    "        self.predictions = [] #list to store preds during lifetime of the simulation\n",
    "        self.counter = 0 # counter for shown images during lifetime of the simulation\n",
    "        self.mod = mod # binary, True if train mod, False for test mod\n",
    "        self.clocks = [] # clocks list per image to monitor if there are to many params to record and RAM is dying \n",
    "        self.clocks.append(0)\n",
    "        \n",
    "        # never use this\n",
    "        if cheat:\n",
    "            dig_y = y[:int(n_hidden)]\n",
    "            dig_X = X[:int(n_hidden)]\n",
    "            for s in np.arange(int(n_hidden)):\n",
    "                for j in np.arange(int(n_input)):\n",
    "                    # shape dig_X = (n_hidden, n_input)\n",
    "                    # shape inp_syn is a vectorized matrix\n",
    "                    # W_11 ..... W_n1\n",
    "                    # ..\n",
    "                    # W_1m ..... W_nm\n",
    "                    # where n is post length, m is pre length\n",
    "                    self.input_syn.w[s+j*int(n_hidden)] = dig_X[s][j]\n",
    "            print ('ALARRRM !!! CHEATER !!! I used cheat initialisation')\n",
    "    \n",
    "    def random_init_groups(self, groups, trains):\n",
    "        '''\n",
    "        random inits for a and theta of neuron groups + setting trains for neuron groups\n",
    "        groups - list of NeuronGroup objects, trains - list of train values (Ex. [1, 1, 1] if all are trainable)'''\n",
    "        if self.high_verbosity:\n",
    "            print ()\n",
    "        for group,tr in zip(groups, trains):\n",
    "            if tr:\n",
    "                group.train = np.ones_like(group.train)\n",
    "                if self.high_verbosity:\n",
    "                    print (group.name + ' ' + str(group.N) + ' trainable')\n",
    "            else:\n",
    "                group.train = np.zeros_like(group.train)\n",
    "                if self.high_verbosity:\n",
    "                    print (group.name + ' non-trainable')\n",
    "            group.a = np.random.rand(len(group))*0.5\n",
    "            group.theta = np.random.rand(len(group))*0.5\n",
    "        if self.high_verbosity:\n",
    "            print ()\n",
    "    \n",
    "    def create_synapse(self, name, pre, post, eqs, on_pre, on_post, distribution = 'equal_[0,1]', condition = None):\n",
    "        \n",
    "        '''\n",
    "        AUTO-creating synapses between pre and post NeuronGroup with name='name'\n",
    "        eqs, on_pre, on_post -  standart parameteres for Synapses\n",
    "        distribution - string, initial values for weights\n",
    "        condition - string, some cpecific conditions for connecting, same as in connect() method for Synapses\n",
    "        extra value for conditions is 'reciprocal'. Should be used if Synapse object has w_rec reciprocal weights'''\n",
    "        \n",
    "        exec('self.'+ name + '= Synapses(pre, post, eqs, on_pre = on_pre, on_post = on_post, dt = time_step)')\n",
    "        if self.high_verbosity:\n",
    "            print ('{} -> {}, initial distribution = {}'.format(pre.name, post.name, distribution))\n",
    "        if condition:\n",
    "            if condition == 'reciprocal':\n",
    "                exec('self.'+ name + '.connect()')\n",
    "            else:\n",
    "                exec('self.'+ name + \".connect(condition = '\" + condition +\"')\")\n",
    "        else: \n",
    "            exec('self.'+ name + '.connect()')\n",
    "        \n",
    "        if distribution:\n",
    "            flag = 0\n",
    "        if distribution == 'equal_[0,1]':    \n",
    "            exec('self.' + name +'.w = np.random.random(len(pre)*len(post))')\n",
    "            flag = 1\n",
    "        if distribution == 'equal_[-1,1]'and condition == 'i!=j':\n",
    "            exec('self.' + name +'.w = (np.random.random(len(pre)*(len(post)-1)) - 0.5) * 2.')\n",
    "            flag = 1\n",
    "        if distribution == 'equal_[-1,0]'and condition == 'i!=j':\n",
    "            exec('self.' + name +'.w = (np.random.random(len(pre)*(len(post)-1)) - 1.)')  \n",
    "            flag = 1\n",
    "        if distribution == 'norm':\n",
    "            exec('self.' + name +'.w = np.random.randn(len(pre)*len(post))')\n",
    "            flag = 1\n",
    "        if distribution == 'zeros':\n",
    "            exec('self.' + name +'.w = np.zeros_like(self.' + name +'.w)')     \n",
    "            flag = 1\n",
    "        if distribution == 'ones':\n",
    "            exec('self.' + name +'.w = np.ones_like(self.' + name +'.w)')\n",
    "            flag = 1\n",
    "            \n",
    "        if condition == 'reciprocal':\n",
    "            exec('self.' + name +'.w_rec = np.array(self.' + name +'.w).transpose()')\n",
    "            flag = 1\n",
    "        \n",
    "        if self.high_verbosity and flag==0:\n",
    "            print ('SOMETHING WENT WRONG, check your distribution and condition paramaeters: {}, {}'.format(distribution, condition))\n",
    "        \n",
    "        \n",
    "    def sample_data(self):\n",
    "        '''\n",
    "        Sampling random X vector from X and correspondinf label from y\n",
    "        '''\n",
    "        sample = np.random.randint(0, self.X.shape[0])\n",
    "        self.clocks.append(clock())\n",
    "        return self.X[sample], self.y[sample]\n",
    "\n",
    "    def update_func(self):\n",
    "            \n",
    "        # active phase\n",
    "        if self.counter % 2 == 0:\n",
    "        \n",
    "            image_sample, label_sample = self.sample_data()\n",
    "            if self.high_verbosity:\n",
    "                print ('Processing {} image with label {}'.format(self.counter/2, label_sample))\n",
    "\n",
    "            self.P.rates = [k*250*Hz for k in image_sample]\n",
    "            self.M.rates = [(1-k)*250*Hz for k in image_sample]\n",
    "            if self.mod:\n",
    "                self.H.I_teacher = np.zeros_like(self.H.I_teacher)\n",
    "                self.H.I_teacher[int(label_sample)] = Teacher_amplitude\n",
    "                #self.H.train = np.zeros_like(self.H.train)\n",
    "                #self.H.train[int(label_sample)] = 1.\n",
    "            else: \n",
    "                self.H.I_teacher = np.zeros_like(self.H.I_teacher)\n",
    "                self.H.train = np.zeros_like(self.H.train)\n",
    "            # saving shown labels\n",
    "            self.shown_labels.append(int(label_sample))\n",
    "        \n",
    "        # resting phase\n",
    "        else:\n",
    "            self.P.rates = np.zeros_like(self.P.rates)\n",
    "            self.M.rates = np.zeros_like(self.M.rates)\n",
    "            self.H.I_inp = np.zeros_like(self.H.I_inp)\n",
    "            self.H.I_intr = np.zeros_like(self.H.I_intr)\n",
    "            if self.mod:\n",
    "                self.H.I_teacher = np.zeros_like(self.H.I_teacher)\n",
    "                #self.H.train = np.zeros_like(self.H.train)\n",
    "                \n",
    "            # saving predictions\n",
    "            pred = np.argmax(np.mean(self.StateMonitorH.a[:,-int(time_per_image/(2.*ms)):], axis=1))\n",
    "            self.predictions.append(pred)\n",
    "            if self.high_verbosity:\n",
    "                #print(self.StateMonitorH['a'][:,-1])\n",
    "                print(np.max(self.StateMonitorH.a[:,-1]))\n",
    "                print(np.max(self.StateMonitorH.I_inp[:,-1]))\n",
    "                print(np.min(self.StateMonitorH.I_intr[:,-1]))\n",
    "                if self.predictions[-1] == self.shown_labels[-1]:\n",
    "                    print ('correct', pred)\n",
    "                else:\n",
    "                    print ('incorrect', pred)\n",
    "        self.counter += 1\n",
    "\n",
    "    def run(self, runtime):\n",
    "        self.network.run(runtime)\n",
    "        \n",
    "    def save_weights(self, path, encoding=\"cp1251\"):\n",
    "        print (\"сохранение сети в файл\", path)\n",
    "        weights = {}\n",
    "        weights['Input_weights'] = list(self.input_syn.w)\n",
    "        weights['Intrinsic_output_weights'] = list(self.intrinsic_output_syn.w)\n",
    "        weights['Input_inverse_weights'] = list(self.input_inverse_syn.w)\n",
    "        \n",
    "        sv_json(weights, path, encoding=encoding)\n",
    "    \n",
    "    def load_weights(self, path, encoding=\"cp1251\"):\n",
    "        print (\"загрузка сети из файла\", path)\n",
    "        weights = ld_json(path, encoding=encoding)\n",
    "        self.input_syn.w = weights['Input_weights']\n",
    "        self.intrinsic_output_syn.w = weights['Intrinsic_output_weights']\n",
    "        self.input_inverse_syn.w = weights['Input_inverse_weights']\n",
    "        \n",
    "    def plot_clocks(self):\n",
    "        '''\n",
    "        Plot values of np.diff(self.clocks) to look of there are some errors during \"run\". If there \n",
    "        are huge picks in the middle of simulation on this graph, than it is likely that there are to \n",
    "        much recording variables or neurons in Monitors.\n",
    "        '''\n",
    "        figure('plot_clocks')\n",
    "        plot(np.arange(1, len(self.clocks)), np.diff(self.clocks))\n",
    "        if self.high_verbosity:\n",
    "            print('INIT', np.sum(np.diff(self.clocks))[:2])\n",
    "            print('MEAN', np.mean(np.diff(self.clocks)[2:]), 'STD', np.std(np.diff(self.clocks))[2:])\n",
    "        show()\n",
    "    \n",
    "    def plot_H(self, variables, interval, neuron_indexes):\n",
    "        '''\n",
    "        Plotting all recording variables for H group on 'interval' period for 'neuron_indexes' neurons.\n",
    "        Note that neuron_indexes is a sub-list from monitor['H'][2] list (remember if it was 'True', than all neurons \n",
    "        of this NeuronGroup were recorded)\n",
    "        '''\n",
    "        figure('H', figsize=(10, len(variables)*5))\n",
    "        for _, m in enumerate(variables):\n",
    "            subplot(len(variables), 1, _+1)\n",
    "            title(m)\n",
    "            for j in neuron_indexes:\n",
    "                exec('plot(interval, self.StateMonitorH.'+str(m)+'[j][interval[0]:interval[-1]+1], label = str(j))')\n",
    "            legend(loc='best')\n",
    "        show()\n",
    "        \n",
    "    def plot_weights(self, weights_type, interval, weights_indexes):\n",
    "        '''\n",
    "        Plotting weights evolution for 'weights_type' on 'interval' period of time for 'weights_indexes' weights.\n",
    "        Note that weights_indexes is a sub-list from monitor[$weights_type][2] list (remember if it was 'True', than all weights \n",
    "        of this type in this Synapse are recorded)\n",
    "        '''\n",
    "        \n",
    "        if weights_type == 'Input_weights':\n",
    "            if self.SynapseMonitorInput:\n",
    "                values = self.SynapseMonitorInput.w\n",
    "            else:\n",
    "                raise NameError('There was no record of this synapse')\n",
    "            \n",
    "        elif weights_type == 'Input_inverse_weights':\n",
    "            if self.SynapseMonitorInputInverse:\n",
    "                values = self.SynapseMonitorInputInverse.w\n",
    "            else:\n",
    "                raise NameError('There was no record of this synapse')\n",
    "        \n",
    "        elif weights_type == 'Intrinsic_output_weights':\n",
    "            if self.SynapseMonitorIntrinsicOutput:\n",
    "                values = self.SynapseMonitorIntrinsicOutput.w\n",
    "            else:\n",
    "                raise NameError('There was no record of this synapse')\n",
    "        else:\n",
    "            raise NameError('Incorrect weights_type')\n",
    "        \n",
    "        \n",
    "        figure(weights_type, figsize=(10, 5))\n",
    "        title(weights_type)\n",
    "        for j in weights_indexes:\n",
    "            plot(interval, values[j], label = str(j))\n",
    "        #legend(loc='best')\n",
    "        show()\n",
    "        \n",
    "    def imshow_forward_weights(self, gr, N, M, n, m):\n",
    "        '''\n",
    "        Plotting forward weights of 'gr' NeuronGroup on one figure.\n",
    "        gr - 'H'\n",
    "        N, M - height and width of figure in subplots\n",
    "        n, m - height and width of weight image\n",
    "        '''\n",
    "\n",
    "        if gr == 'H':\n",
    "            group1 = self.P\n",
    "            group2 = self.H\n",
    "            group3 = self.M\n",
    "            name1 = 'imshow_input_weights'\n",
    "            name2 = 'imshow_input_inverse_weights'\n",
    "            np_images1 = np.array(self.input_syn.w)\n",
    "            np_images2 = np.array(self.input_inverse_syn.w)\n",
    "        else:\n",
    "            raise NameError('No such group')\n",
    "\n",
    "        images_shape1=[len(group1), len(group2)]\n",
    "        self.one_image(np_mts=np_images1, mts_shape=images_shape1, N=N, M=M, n=n, m=m, frame=None,\n",
    "                       name=name1)\n",
    "        \n",
    "        images_shape2=[len(group3), len(group2)]\n",
    "        self.one_image(np_mts=np_images2, mts_shape=images_shape2, N=N, M=M, n=n, m=m, frame=None,\n",
    "                       name=name2)\n",
    "        \n",
    "    \n",
    "    def imshow_intrinsic_weights(self, gr, N, M, n, m):\n",
    "        '''\n",
    "        Plotting intrinsic weights of 'gr' NeuronGroup on one figure.\n",
    "        gr - 'H'\n",
    "        N, M - height and width of figure in subplots\n",
    "        n, m - height and width of weight image\n",
    "        '''\n",
    "        \n",
    "        if gr == 'H':\n",
    "            group = self.H\n",
    "            z = self.intrinsic_output_syn.w\n",
    "        else:\n",
    "            raise NameError('No such group')\n",
    "        \n",
    "        for i in np.arange(int(len(group))):\n",
    "            z = insert(z, i+int(len(group))*i, 0)\n",
    "    \n",
    "        np_mts = np.array(z)\n",
    "        mts_shape=[len(group), len(group)]\n",
    "        \n",
    "        self.one_image(np_mts=np_mts, mts_shape=mts_shape, N=N, M=M, n=n, m=m, intrinsic=True, \n",
    "                       name='imshow_intrinsic_weights')\n",
    "        \n",
    "    def one_image(self, np_mts, mts_shape, N, M, n, m, frame=None, intrinsic=False, name=None, video=False):\n",
    "        '''\n",
    "        Plotting image of np_mts frame\n",
    "        np_mts - numpy array of multivariate timeseries (or just numpy array for fixed frame)\n",
    "        mts_shape - list [amount of neurons in pre group, amount of neurons in post group]\n",
    "        frame - frame of timeseries, None if np_mts is just numpy array of weights instead of synapse monitor mts\n",
    "        N, M - height and width of figure in \"subplots\"\n",
    "        n, m - height and width of weight image\n",
    "        intrinsic - True if visualising intrinsic weights\n",
    "        name - unique name of the figure\n",
    "        '''\n",
    "        if intrinsic:\n",
    "            images = np.array(np_mts).reshape(int(mts_shape[1]), int(n), int(m))\n",
    "        else:\n",
    "            images = [[np_mts[r + j * int(mts_shape[1])][frame]\n",
    "                        for j in np.arange(mts_shape[0])] \n",
    "                        for r in np.arange(mts_shape[1])]\n",
    "            images = np.array(images).reshape(int(mts_shape[1]), int(n), int(m))\n",
    "\n",
    "        horizontal_lines = np.ones((1, M*(m+1)+1))*(np.nan)\n",
    "\n",
    "        for i in np.arange(N):\n",
    "            horizontal_line = np.ones((images[0].shape[0],1))*(np.nan)\n",
    "            for j in np.arange(M):\n",
    "                im = np.hstack((images[int(j+i*M)],np.ones((images[int(j+i*M)].shape[0],1))*(np.nan)))\n",
    "                horizontal_line = np.hstack((horizontal_line, im))\n",
    "            horizontal_line = np.vstack((horizontal_line, np.ones((1, M*(m+1)+1))*(np.nan)))\n",
    "            horizontal_lines = np.vstack((horizontal_lines, horizontal_line))\n",
    "        \n",
    "        if video:\n",
    "            return horizontal_lines\n",
    "        else:\n",
    "            figure(name, figsize=(4, 4*N/M))\n",
    "            title(name)\n",
    "            imshow(horizontal_lines, interpolation=None, cmap='winter')\n",
    "            colorbar()\n",
    "            axis('off')\n",
    "            show()\n",
    "\n",
    "    def animate_input_weights(self, name, N, M, n, m, start=0, end=None):\n",
    "        group1 = self.P\n",
    "        group2 = self.H\n",
    "        np_images = np.array(self.SynapseMonitorInput.w)\n",
    "        images_shape=[len(group1), len(group2)]\n",
    "        if end:\n",
    "            pass\n",
    "        else:\n",
    "            end = self.SynapseMonitorInput.w.shape[1]-1\n",
    "        \n",
    "        print (end)\n",
    "        NN.animate_weights(name, np_mts=np_images, mts_shape=images_shape, start=start, end=end,\n",
    "                           N=N, M=M, n=n, m=m, intrinsic=False)\n",
    "        \n",
    "    def animate_input_inverse_weights(self, name, N, M, n, m, start=0, end=None):\n",
    "        group1 = self.M\n",
    "        group2 = self.H\n",
    "        np_images = np.array(self.SynapseMonitorInputInverse.w)\n",
    "        images_shape=[len(group1), len(group2)]\n",
    "        if end:\n",
    "            pass\n",
    "        else:\n",
    "            end = self.SynapseMonitorInputInverse.w.shape[1]-1\n",
    "        \n",
    "        print (end)\n",
    "        NN.animate_weights(name, np_mts=np_images, mts_shape=images_shape, start=start, end=end,\n",
    "                           N=N, M=M, n=n, m=m, intrinsic=False)\n",
    "   \n",
    "    def animate_weights(self, name, np_mts, mts_shape, start, end, N, M, n, m, intrinsic=False):\n",
    "\n",
    "        def frames_generator(np_mts, mts_shape, start, end, N, M, n, m, intrinsic=False):\n",
    "            '''\n",
    "            generator for speed and RAM economy(hope it helps)\n",
    "            '''\n",
    "            frame = start\n",
    "            while frame < end:\n",
    "                image_frame = self.one_image(np_mts, mts_shape, N, M, n, m, \n",
    "                                             frame=frame, intrinsic=intrinsic, video=True)\n",
    "                frame += 1\n",
    "                yield image_frame\n",
    "        \n",
    "        def update(data):\n",
    "            mat.set_data(data)\n",
    "            return mat \n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        mat = ax.imshow(self.one_image(np_mts[:,0], mts_shape, N, M, n, m, \n",
    "                                       frame=None, intrinsic=intrinsic, video=True),cmap=\"winter\",interpolation=None)\n",
    "        plt.colorbar(mat)\n",
    "        plt.axis('off')\n",
    "        print ('im here')\n",
    "        ani = animation.FuncAnimation(fig, update, frames_generator(np_mts, mts_shape, start, end, N, M, n, m, intrinsic=False), \n",
    "                                      interval=10, save_count=end-2)\n",
    "        print ('saving file ', name +'.mp4')\n",
    "        ani.save(name+'.mp4',writer=animation.FFMpegFileWriter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "inits=None\n",
    "monitor = {} # dict with names of objects to record and their parameters\n",
    "monitor['H'] = {'variables':['a'], 'dt':1*ms, 'record':True}\n",
    "#monitor['H'] = {'variables':['I_inp','I_intr','I','a'], 'dt':1*ms, 'record':True}\n",
    "#monitor['Intrinsic_output_weights'] ={'variables':['w'], 'dt':50*ms, 'record':True}\n",
    "#monitor['Input_weights'] ={'variables':['w'], 'dt':50*ms, 'record':True}\n",
    "classes = int(len(set(y)))\n",
    "n_input = int(X.shape[1])\n",
    "\n",
    "\n",
    "#params_to_optimize = [alpha, beta, lr, lr_intr, c_inp, c_intr_out, c_diff, Teacher_amplitude]\n",
    "\n",
    "#NN = Perceptron(X, y, params_to_optimize, inits=inits, monitor=monitor, mod=True, high_verbosity=True)\n",
    "for j in np.arange(1000):\n",
    "    \n",
    "    alpha = np.random.choice([10, 15, 20, 25, 30])*ms\n",
    "    beta = np.random.choice([80, 90, 100, 110, 120, 130, 140, 150])*ms\n",
    "    lr = 0.1\n",
    "    lr_intr = 0.1\n",
    "    c_inp = np.random.choice([0.1, 0.3, 0.5, 0.75, 1.0])\n",
    "    c_intr_out = c_inp*np.random.choice([0, 1, 10, 25, 35, 50, 75])\n",
    "    c_diff = np.random.choice([1.0, 1.1, 1.2])\n",
    "    Teacher_amplitude = c_inp*np.random.choice([25,50,100,150,200])\n",
    "\n",
    "    params_to_optimize = {}\n",
    "    params_to_optimize['alpha'] = alpha\n",
    "    params_to_optimize['beta'] = beta\n",
    "    params_to_optimize['lr'] = lr\n",
    "    params_to_optimize['lr_intr'] = lr_intr\n",
    "    params_to_optimize['c_inp'] = c_inp\n",
    "    params_to_optimize['c_intr_out'] = c_intr_out\n",
    "    params_to_optimize['c_diff'] = c_diff\n",
    "    params_to_optimize['Teacher_amplitude'] = Teacher_amplitude\n",
    "\n",
    "    NN = Perceptron(X, y, params_to_optimize, inits=inits, monitor=monitor, mod=True, high_verbosity=False)\n",
    "    \n",
    "    print ('SIMULATION', j, params_to_optimize)\n",
    "    NN.mod = True\n",
    "    print('train')\n",
    "    NN.run(80000*ms) #400\n",
    "    NN.mod = False\n",
    "    print('test')\n",
    "    NN.run(20000*ms) #100\n",
    "    tries = [accuracy_score(NN.shown_labels[-100:], NN.predictions[-100:]), params_to_optimize]\n",
    "    accuracies.append(tries)\n",
    "    #accuracies.append(accuracy_score(NN.shown_labels[-100:], NN.predictions[-100:]))\n",
    "    print (accuracies[-1][0])\n",
    "\n",
    "accs = []\n",
    "for acc in accuracies:\n",
    "    accs.append(acc[0])\n",
    "\n",
    "\n",
    "print (accuracies[np.argmax(accs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0.9 SIMULATION 8 {'alpha': 25. * msecond, 'beta': 150. * msecond, 'lr': 0.1, 'lr_intr': 0.1, 'c_inp': 0.10000000000000001, 'c_intr_out': 1.0, 'c_diff': 1.1000000000000001, 'Teacher_amplitude': 15.0}\n",
    "#0.88 SIMULATION 16 {'alpha': 30. * msecond, 'beta': 110. * msecond, 'lr': 0.1, 'lr_intr': 0.1, 'c_inp': 1.0, 'c_intr_out': 1.0, 'c_diff': 1.2, 'Teacher_amplitude': 150.0}\n",
    "#0.87 SIMULATION 12 {'alpha': 25. * msecond, 'beta': 90. * msecond, 'lr': 0.1, 'lr_intr': 0.1, 'c_inp': 0.5, 'c_intr_out': 5.0, 'c_diff': 1.0, 'Teacher_amplitude': 12.5}\n",
    "#0.82 SIMULATION 14 {'alpha': 30. * msecond, 'beta': 130. * msecond, 'lr': 0.1, 'lr_intr': 0.1, 'c_inp': 0.10000000000000001, 'c_intr_out': 0.10000000000000001, 'c_diff': 1.2, 'Teacher_amplitude': 10.0}\n",
    "#0.75 SIMULATION 5 {'alpha': 25. * msecond, 'beta': 120. * msecond, 'lr': 0.1, 'lr_intr': 0.1, 'c_inp': 0.29999999999999999, 'c_intr_out': 0.0, 'c_diff': 1.2, 'Teacher_amplitude': 30.0}\n",
    "#0.75 {'alpha': 25. * msecond, 'beta': 110. * msecond, 'lr': 0.1, 'lr_intr': 0.1, 'c_inp': 0.3, 'c_intr_out': 3.0, 'c_diff': 1.1, 'Teacher_amplitude': 25.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.plot_clocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.imshow_forward_weights('H', 5, 2, 5, 5)\n",
    "NN.imshow_intrinsic_weights('H', 5, 2, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NN.plot_H(monitor['H']['variables'], np.arange(55000,60000), np.arange(len(NN.H)))\n",
    "NN.plot_H(monitor['H']['variables'], NN.StateMonitorH.t/ms, np.arange(len(NN.H)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.plot_weights('Input_weights', NN.SynapseMonitorInput.t/ms, np.arange(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.plot_weights('Intrinsic_output_weights', NN.SynapseMonitorIntrinsicOutput.t/ms, np.arange(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN.save_weights('./Stupid_digits_saved_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
